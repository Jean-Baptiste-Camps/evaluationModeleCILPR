{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c84d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "##tentative implémentation code Thibault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6c6a3915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from thibaultScript import (\n",
    "    import_known_tokens,\n",
    "    compile_scores#,\n",
    "#    convert_raw#,\n",
    "#    vjui\n",
    ")\n",
    "\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "626249a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_raw(gold, task_list=[], \n",
    "                form_fn=lambda x: x, \n",
    "                lemma_fn=lambda x: x, \n",
    "                pos_fn=lambda x: x,\n",
    "                pos_key = \"POS\",\n",
    "                remove_disambiguation = False\n",
    "               ):\n",
    "    \"\"\" Converts input data into Gold data.\n",
    "        The main goal here is to treat cases like apostrophes, so that two tokens _l/'_\n",
    "        became one _l'_\n",
    "        And handle fucking roman numerals\n",
    "    \"\"\"\n",
    "    temp_out = []\n",
    "    pass_next = False\n",
    "    \n",
    "    for sentence in tqdm(gold):\n",
    "        temp_sentence = []\n",
    "        no_sentence_append = False\n",
    "        # Handle roman numerals\n",
    "        for idx,token in enumerate(sentence):\n",
    "            if pass_next:\n",
    "                pass_next = False\n",
    "                continue\n",
    "            \n",
    "            new_token = {task: \"_\" for task in task_list}\n",
    "            new_token.update({\n",
    "                \"form\": form_fn(token[\"form\"]),\n",
    "                \"lemma\": lemma_fn(token[\"lemma\"]),\n",
    "                \"POS\": pos_fn(token[pos_key]),\n",
    "            })\n",
    "            # No disambiguation at the lemmatizer lever\n",
    "            if remove_disambiguation and new_token[\"lemma\"][-1].isnumeric():\n",
    "                new_token[\"lemma\"] = new_token[\"lemma\"][:-1]\n",
    "                \n",
    "            if new_token[\"form\"] in {\"’\", \"'\"} and temp_sentence:\n",
    "                temp_sentence[-1][\"form\"] += \"'\"\n",
    "                \n",
    "            # roman numerals\n",
    "            # not useful now, because we do it when loading sentences\n",
    "            # but might serve someday\n",
    "            elif (\n",
    "                # is there a phrase before, and does it ends with .\n",
    "                temp_out and temp_out[-1] and temp_out[-1][-1][\"form\"] == \".\"\n",
    "                # and are we at the start of a sentence, and not the end\n",
    "                and idx == 0 and idx < (len(sentence) - 1) \n",
    "                # and next token a .\n",
    "                and sentence[idx+1][\"form\"] == '.'\n",
    "                and token[pos_key].endswith(\"car\")\n",
    "            ):\n",
    "                new_token[\"form\"] = \".\"+new_token[\"form\"]+\".\"\n",
    "                temp_out[-1][-1] = new_token\n",
    "                # and now some acrobatics\n",
    "                pass_next = True\n",
    "                temp_sentence = temp_out[-1]\n",
    "                no_sentence_append = True\n",
    "                \n",
    "            else:\n",
    "                temp_sentence.append(new_token)\n",
    "        if not no_sentence_append:\n",
    "            temp_out.append(temp_sentence)\n",
    "    return temp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1bebd2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_TOKENS, KNOWN_LEMMAS = import_known_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9156d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNOWN_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7abca14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASKS = \"lemma,Deg,Numb,Person,Mood_Tense_Voice,Case,Gend,pos\".split(\",\")\n",
    "TASKS = \"lemma,POS\".split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d8c0942e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278 texts found\n",
      "1626 sentences found\n"
     ]
    }
   ],
   "source": [
    "Texts = []\n",
    "GOLD = []\n",
    "\n",
    "nb_tokens = 0\n",
    "\n",
    "def filter_gold(data):\n",
    "    return [lst for lst in data if lst]\n",
    "\n",
    "\n",
    "import regex\n",
    "\n",
    "punkts = regex.compile(r\"\\W+\")\n",
    "greek = regex.compile(r\"\\p{Greek}+\")\n",
    "\n",
    "def keep_tokens(token):\n",
    "    if greek.match(token):\n",
    "        print(token)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "with open(\"nca-sample-naomicorr.tsv\") as f:\n",
    "    header = []\n",
    "    current_text = None\n",
    "    for lineno, line in enumerate(f):\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        if lineno == 0:\n",
    "            header = line\n",
    "            continue\n",
    "        \n",
    "        line = dict(zip(header, line))\n",
    "        \n",
    "        if line[\"form\"].startswith(\"[REF:\"):\n",
    "            GOLD = filter_gold(GOLD)\n",
    "            Texts.append((line[\"form\"], nb_tokens, len(GOLD)))\n",
    "            GOLD.append([])\n",
    "            continue\n",
    "        \n",
    "        if line[\"POS\"] == \"PONfrt\":\n",
    "            if GOLD[-1] != []:\n",
    "                # And now for some more Roman Numerals\n",
    "                if GOLD[-1][-1][\"POS\"].endswith(\"car\") and line[\"form\"] == '.':\n",
    "                    GOLD[-1].append(line)\n",
    "                else:\n",
    "                    GOLD[-1].append(line)\n",
    "                    GOLD = filter_gold(GOLD)\n",
    "                    GOLD.append([])\n",
    "        elif keep_tokens(line[\"form\"]):\n",
    "            GOLD[-1].append(line)\n",
    "            nb_tokens += 1\n",
    "            \n",
    "\n",
    "if GOLD[-1] == []:\n",
    "    GOLD = GOLD[:-1]\n",
    "print(f\"{len(Texts)} texts found\")\n",
    "print(f\"{len(GOLD)} sentences found\")\n",
    "TextsLengths = {\n",
    "    \n",
    "}\n",
    "# Compute texts Lengths\n",
    "for cur, nxt in zip(Texts, Texts[1:] + [None]):\n",
    "    if nxt is None:\n",
    "        TextsLengths[cur[0]] = nb_tokens - cur[1]\n",
    "    else:\n",
    "        TextsLengths[cur[0]] = nxt[1] - cur[1]\n",
    "# Update titles\n",
    "#TextsTitles = {\n",
    "#    urn: f\"{title} ({TextsLengths.get(urn, '?')} mots)\"\n",
    "#    for urn, title in TextsTitles.items()\n",
    "#}\n",
    "#print(TextsTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c3841e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextsTitles = [t[5:-1] for t in TextsLengths.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8d3738e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChastVergiS_A_69',\n",
       " 'PsLorrA_672',\n",
       " 'PerNeslesTabJ_602',\n",
       " 'MerlinP_956',\n",
       " 'MerlinP_1603']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextsTitles[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ba40eb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 1626/1626 [00:00<00:00, 18753.77it/s]\n"
     ]
    }
   ],
   "source": [
    "PLATINUM = convert_raw(GOLD, form_fn = lambda x: x.replace('§', '')) #convert_raw(GOLD, task_list=TASKS, lemma_fn=lambda x:x, form_fn=lambda x:x, \n",
    "                #       pos_fn=lambda x:x, clitics_starts_with_accollade=True,\n",
    "                #      clitics_are_duplicate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4fc44741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Longue',\n",
       " 'atente',\n",
       " 'vous',\n",
       " 'poroit',\n",
       " 'nuire',\n",
       " ',',\n",
       " 'ce',\n",
       " \"m'\",\n",
       " 'est',\n",
       " 'vis',\n",
       " ':',\n",
       " 'si',\n",
       " 'lo',\n",
       " 'que',\n",
       " 'vous',\n",
       " 'soiiés',\n",
       " 'amis',\n",
       " 'en',\n",
       " 'un',\n",
       " 'haut',\n",
       " 'liu',\n",
       " ',',\n",
       " 'se',\n",
       " 'vous',\n",
       " 'veés',\n",
       " 'que',\n",
       " 'vous',\n",
       " 'i',\n",
       " 'soiiés',\n",
       " 'bien',\n",
       " 'amés',\n",
       " '.']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS = [\n",
    "    [x[\"form\"] for x in sentence]\n",
    "    for sentence in PLATINUM\n",
    "]\n",
    "# Vérif romains\n",
    "#[t for s in TOKENS for t in s if t[0] == '.']\n",
    "# vérif tokens\n",
    "TOKENS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "68d4a3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lemma', 'POS']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "22b57785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [01:33,  3.75s/it]\n"
     ]
    }
   ],
   "source": [
    "from pie.tagger import Tagger\n",
    "from pie.utils import chunks\n",
    "DEVICE = \"cpu\"\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "OUTPUT = []\n",
    "TEST_NEW = True\n",
    "\n",
    "#tagger = Tagger(device=\"cuda\", batch_size=100, lower=False, tokenize=False)\n",
    "tagger = Tagger(device=DEVICE, batch_size=BATCH_SIZE, lower=False, tokenize=False)\n",
    "if TEST_NEW:\n",
    "    for task in TASKS:\n",
    "        tagger.add_model(f\"modeles/{task}.tar\", task)\n",
    "#else:\n",
    "#    tagger.add_model(\"../../../latin-lasla-models/lasla-plus.tar\", *TASKS)\n",
    "\n",
    "\n",
    "for chunk in tqdm(chunks([(sent, len(sent)) for sent in TOKENS], tagger.batch_size)):\n",
    "    tagged, tasks = tagger.tag(*zip(*chunk))#, use_beam=True)\n",
    "    OUTPUT.extend([\n",
    "        [\n",
    "            (token, dict(zip(tasks, result)))\n",
    "            for token, result in sentence\n",
    "        ]\n",
    "        for sentence in tagged\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "064a1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "RESULTS, RAW_SCORES, RAW_SCORES_NOT_EMPTY, ERRORS, SCORES_KNOWN = compile_scores(\n",
    "    OUTPUT, PLATINUM, task_list=TASKS, known_tokens=KNOWN_TOKENS, known_lemmas=KNOWN_LEMMAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "965135e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>93.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma</th>\n",
       "      <td>91.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tabulate import tabulate\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "data = [[\"Task\", \"Accuracy\"]]#, \"Accuracy on V != _\"]]\n",
    "\n",
    "\n",
    "for task, (pred, truth) in RAW_SCORES.items():\n",
    "    (pred_limited, truth_limited) = RAW_SCORES_NOT_EMPTY[task]\n",
    "    data.append([\n",
    "        task,\n",
    "        \"{0:.2f}\".format(accuracy_score(truth, pred)*100)#,\n",
    "        #\"{0:.2f}\".format(accuracy_score(pred_limited, truth_limited)*100)\n",
    "    ])\n",
    "    \n",
    "df = DataFrame([x[1:] for x in data[1:]], columns=data[0][1:], index=[x[0] for x in data[1:]]).sort_index()\n",
    "display(HTML(df.to_html()))\n",
    "#print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e4ce51",
   "metadata": {},
   "source": [
    "## ACCURACY PAR TEXTE PAS INTÉRESSANTE ICI: textes trop courts\n",
    "MilestonesSentences = [\n",
    "    (tid, begin, end)\n",
    "    for (tid, _, begin), (_, _, end) in zip(Texts, Texts[1:]+[(None, None, None)])\n",
    "] # Those are sentences IDs\n",
    "\n",
    "def count_tokens(begin, end):\n",
    "    return len([tok for sent in PLATINUM[begin:end] for tok in sent])\n",
    "\n",
    "MILESTONES = [count_tokens(beg, end) for _, beg, end in MilestonesSentences]\n",
    "MILESTONES = [sum(MILESTONES[:index]) + value for index, value in enumerate(MILESTONES)]\n",
    "\n",
    "SPLITS_TASK = {\n",
    "    task: []\n",
    "    for task in RAW_SCORES\n",
    "}\n",
    "SIZES = []\n",
    "\n",
    "\n",
    "lengths = []\n",
    "support_done = False\n",
    "for task, (pred, truth) in RAW_SCORES.items():\n",
    "    ms_start = 0\n",
    "    for milestone in MILESTONES:\n",
    "        SPLITS_TASK[task].append(accuracy_score(truth[ms_start:milestone], pred[ms_start:milestone]))\n",
    "        length = milestone - ms_start + 1\n",
    "        if not support_done:\n",
    "            SIZES.append(length)\n",
    "        ms_start = milestone\n",
    "    support_done = True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae4b27",
   "metadata": {},
   "source": [
    "MilestonesSentences[1][0]\n",
    "#MILESTONES\n",
    "#SIZES\n",
    "#TextsTitles[tid]\n",
    "#TextsTitles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a15723",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "sns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'})\n",
    "\n",
    "DF_Tardif = DataFrame(SPLITS_TASK, index=[\n",
    "    #\"{} ({} mots)\".format(TextsTitles[tid], length) for (tid, *_), length in zip(MilestonesSentences, SIZES)\n",
    "    \"{} ({} mots)\".format(TextsTitles[0], length) for (*_), length in zip(MilestonesSentences, SIZES)\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "cmap = sns.cubehelix_palette(250, hue=0.05, rot=0, light=1, dark=0, as_cmap=True)\n",
    "ax = sns.heatmap(DF_Tardif, annot=True, cmap=cmap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5b72af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Dict[Text_id, Dict[POS, [0, 1]]] where 0 = false, 1 = true\n",
    "Stats_Per_Pos = defaultdict(list)\n",
    "_, Scores_all2, *_, Score_Knowns = compile_scores(OUTPUT, PLATINUM, \n",
    "                                                     task_list=TASKS, known_tokens=KNOWN_TOKENS, \n",
    "                                                     known_lemmas=KNOWN_LEMMAS)\n",
    "\n",
    "NBTOKENS = 0\n",
    "NBERRORS = 0\n",
    "\n",
    "for (lemma_pred, lemma_truth,  pos_truth) in zip(\n",
    "   Scores_all2[\"lemma\"][0],\n",
    "   Scores_all2[\"lemma\"][1],\n",
    "   Scores_all2[\"POS\"][1]\n",
    "):\n",
    "    Stats_Per_Pos[pos_truth].append(int(lemma_pred == lemma_truth))\n",
    "    NBTOKENS +=1\n",
    "    NBERRORS += int(lemma_pred != lemma_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "69261898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Impact</th>\n",
       "      <th>Support</th>\n",
       "      <th>Support relatif</th>\n",
       "      <th>Contribution relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NOMpro</td>\n",
       "      <td>0.078731</td>\n",
       "      <td>0.257556</td>\n",
       "      <td>851</td>\n",
       "      <td>0.024923</td>\n",
       "      <td>0.232633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOMcom</td>\n",
       "      <td>0.835802</td>\n",
       "      <td>0.251314</td>\n",
       "      <td>4659</td>\n",
       "      <td>0.136448</td>\n",
       "      <td>0.114867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PROrel</td>\n",
       "      <td>0.788595</td>\n",
       "      <td>0.049934</td>\n",
       "      <td>719</td>\n",
       "      <td>0.021057</td>\n",
       "      <td>0.028877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADJqua</td>\n",
       "      <td>0.847173</td>\n",
       "      <td>0.056833</td>\n",
       "      <td>1132</td>\n",
       "      <td>0.033153</td>\n",
       "      <td>0.023680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VERppe</td>\n",
       "      <td>0.869697</td>\n",
       "      <td>0.042378</td>\n",
       "      <td>990</td>\n",
       "      <td>0.028994</td>\n",
       "      <td>0.013384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DETcar</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>101</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.005583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>VERppa</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.005913</td>\n",
       "      <td>71</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.003834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ADJcar</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.002072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PROind</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>274</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>0.001831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ETR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.001496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>INJ</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.001385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PROcar</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>35</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PROord</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PROint</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>OUT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ADJord</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ABR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PROrel.PROper</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ADJpos</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PROimp</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>PROpos</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>-0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>RED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ADJint</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DETint</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>-0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>PROper.PROper</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>-0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ADJind</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.001643</td>\n",
       "      <td>61</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>-0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ADVgen.PROper</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>-0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DETrel</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>-0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ADVint</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>-0.000293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ADVsub</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>31</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ADVneg.PROper</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>-0.000644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DETdem</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>158</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>-0.001342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VERinf</td>\n",
       "      <td>0.917791</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>815</td>\n",
       "      <td>0.023869</td>\n",
       "      <td>-0.001858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PROdem</td>\n",
       "      <td>0.938719</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>359</td>\n",
       "      <td>0.010514</td>\n",
       "      <td>-0.003287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DETndf</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>179</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>-0.004914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PRE.DETdef</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>357</td>\n",
       "      <td>0.010455</td>\n",
       "      <td>-0.006513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROadv</td>\n",
       "      <td>0.961631</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>417</td>\n",
       "      <td>0.012213</td>\n",
       "      <td>-0.006956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CONsub</td>\n",
       "      <td>0.933266</td>\n",
       "      <td>0.021682</td>\n",
       "      <td>989</td>\n",
       "      <td>0.028965</td>\n",
       "      <td>-0.007283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DETind</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>274</td>\n",
       "      <td>0.008025</td>\n",
       "      <td>-0.008025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DETpos</td>\n",
       "      <td>0.957004</td>\n",
       "      <td>0.010184</td>\n",
       "      <td>721</td>\n",
       "      <td>0.021116</td>\n",
       "      <td>-0.010932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADVgen</td>\n",
       "      <td>0.937471</td>\n",
       "      <td>0.044678</td>\n",
       "      <td>2175</td>\n",
       "      <td>0.063699</td>\n",
       "      <td>-0.019021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ADVneg</td>\n",
       "      <td>0.986945</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>766</td>\n",
       "      <td>0.022434</td>\n",
       "      <td>-0.019149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VERcjg</td>\n",
       "      <td>0.924887</td>\n",
       "      <td>0.114323</td>\n",
       "      <td>4633</td>\n",
       "      <td>0.135686</td>\n",
       "      <td>-0.021363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DETdef</td>\n",
       "      <td>0.982479</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>1541</td>\n",
       "      <td>0.045131</td>\n",
       "      <td>-0.036261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PONfrt</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>1431</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>-0.041581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CONcoo</td>\n",
       "      <td>0.988235</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>1785</td>\n",
       "      <td>0.052277</td>\n",
       "      <td>-0.045378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROper</td>\n",
       "      <td>0.967264</td>\n",
       "      <td>0.027595</td>\n",
       "      <td>2566</td>\n",
       "      <td>0.075150</td>\n",
       "      <td>-0.047555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRE</td>\n",
       "      <td>0.980665</td>\n",
       "      <td>0.016426</td>\n",
       "      <td>2586</td>\n",
       "      <td>0.075736</td>\n",
       "      <td>-0.059310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PONfbl</td>\n",
       "      <td>0.997214</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>3231</td>\n",
       "      <td>0.094626</td>\n",
       "      <td>-0.091669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              POS  Accuracy    Impact  Support  Support relatif  \\\n",
       "24         NOMpro  0.078731  0.257556      851         0.024923   \n",
       "1          NOMcom  0.835802  0.251314     4659         0.136448   \n",
       "16         PROrel  0.788595  0.049934      719         0.021057   \n",
       "0          ADJqua  0.847173  0.056833     1132         0.033153   \n",
       "12         VERppe  0.869697  0.042378      990         0.028994   \n",
       "18         DETcar  0.742574  0.008541      101         0.002958   \n",
       "37         VERppa  0.746479  0.005913       71         0.002079   \n",
       "28         ADJcar  0.578947  0.002628       19         0.000556   \n",
       "20         PROind  0.890511  0.009855      274         0.008025   \n",
       "45            ETR  0.000000  0.001643        5         0.000146   \n",
       "40            INJ  0.700000  0.001971       20         0.000586   \n",
       "38         PROcar  0.800000  0.002300       35         0.001025   \n",
       "23         PROord  0.666667  0.001643       15         0.000439   \n",
       "33         PROint  0.791667  0.001643       24         0.000703   \n",
       "27            OUT  0.000000  0.000657        2         0.000059   \n",
       "31         ADJord  0.869565  0.000986       23         0.000674   \n",
       "46            ABR  0.000000  0.000329        1         0.000029   \n",
       "47  PROrel.PROper  0.000000  0.000329        1         0.000029   \n",
       "36         ADJpos  0.888889  0.000986       27         0.000791   \n",
       "35         PROimp  0.906250  0.000986       32         0.000937   \n",
       "44         PROpos  0.916667  0.000329       12         0.000351   \n",
       "48            RED  1.000000  0.000000        1         0.000029   \n",
       "29         ADJint  1.000000  0.000000        1         0.000029   \n",
       "30         DETint  1.000000  0.000000        3         0.000088   \n",
       "43  PROper.PROper  1.000000  0.000000        4         0.000117   \n",
       "32         ADJind  0.918033  0.001643       61         0.001786   \n",
       "39  ADVgen.PROper  1.000000  0.000000        8         0.000234   \n",
       "41         DETrel  1.000000  0.000000        8         0.000234   \n",
       "42         ADVint  1.000000  0.000000       10         0.000293   \n",
       "34         ADVsub  0.967742  0.000329       31         0.000908   \n",
       "26  ADVneg.PROper  1.000000  0.000000       22         0.000644   \n",
       "25         DETdem  0.936709  0.003285      158         0.004627   \n",
       "4          VERinf  0.917791  0.022011      815         0.023869   \n",
       "6          PROdem  0.938719  0.007227      359         0.010514   \n",
       "10         DETndf  0.994413  0.000329      179         0.005242   \n",
       "22     PRE.DETdef  0.966387  0.003942      357         0.010455   \n",
       "11         PROadv  0.961631  0.005256      417         0.012213   \n",
       "8          CONsub  0.933266  0.021682      989         0.028965   \n",
       "19         DETind  1.000000  0.000000      274         0.008025   \n",
       "14         DETpos  0.957004  0.010184      721         0.021116   \n",
       "7          ADVgen  0.937471  0.044678     2175         0.063699   \n",
       "15         ADVneg  0.986945  0.003285      766         0.022434   \n",
       "3          VERcjg  0.924887  0.114323     4633         0.135686   \n",
       "21         DETdef  0.982479  0.008870     1541         0.045131   \n",
       "13         PONfrt  0.999301  0.000329     1431         0.041910   \n",
       "17         CONcoo  0.988235  0.006899     1785         0.052277   \n",
       "2          PROper  0.967264  0.027595     2566         0.075150   \n",
       "9             PRE  0.980665  0.016426     2586         0.075736   \n",
       "5          PONfbl  0.997214  0.002957     3231         0.094626   \n",
       "\n",
       "    Contribution relative  \n",
       "24               0.232633  \n",
       "1                0.114867  \n",
       "16               0.028877  \n",
       "0                0.023680  \n",
       "12               0.013384  \n",
       "18               0.005583  \n",
       "37               0.003834  \n",
       "28               0.002072  \n",
       "20               0.001831  \n",
       "45               0.001496  \n",
       "40               0.001385  \n",
       "38               0.001275  \n",
       "23               0.001203  \n",
       "33               0.000940  \n",
       "27               0.000598  \n",
       "31               0.000312  \n",
       "46               0.000299  \n",
       "47               0.000299  \n",
       "36               0.000195  \n",
       "35               0.000048  \n",
       "44              -0.000023  \n",
       "48              -0.000029  \n",
       "29              -0.000029  \n",
       "30              -0.000088  \n",
       "43              -0.000117  \n",
       "32              -0.000144  \n",
       "39              -0.000234  \n",
       "41              -0.000234  \n",
       "42              -0.000293  \n",
       "34              -0.000579  \n",
       "26              -0.000644  \n",
       "25              -0.001342  \n",
       "4               -0.001858  \n",
       "6               -0.003287  \n",
       "10              -0.004914  \n",
       "22              -0.006513  \n",
       "11              -0.006956  \n",
       "8               -0.007283  \n",
       "19              -0.008025  \n",
       "14              -0.010932  \n",
       "7               -0.019021  \n",
       "15              -0.019149  \n",
       "3               -0.021363  \n",
       "21              -0.036261  \n",
       "13              -0.041581  \n",
       "17              -0.045378  \n",
       "2               -0.047555  \n",
       "9               -0.059310  \n",
       "5               -0.091669  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LIMIT_TO_POS = {\"VERcjg\", \"VERinf\", \"VERppe\", \"VERppa\", \"NOMcom\", \"ADJqua\"}#LISTE À CONFIRMER\n",
    "\n",
    "\n",
    "def compute_accuracy(trues, corpus_size, corpus_accuracy) -> int:\n",
    "    return ((len(trues) - sum(trues)) / corpus_size) / corpus_accuracy\n",
    "\n",
    "PosLemmaDetails = DataFrame([\n",
    "    {\n",
    "        \"POS\": pos, \n",
    "        \"Accuracy\": sum(equals) / len(equals), \n",
    "        \"Impact\": compute_accuracy(equals, NBTOKENS, NBERRORS/NBTOKENS),\n",
    "        \"Support\": len(equals),\n",
    "        \"Support relatif\": len(equals) / NBTOKENS,\n",
    "        \"Contribution relative\": compute_accuracy(equals, NBTOKENS, NBERRORS/NBTOKENS) - len(equals) / NBTOKENS\n",
    "    }\n",
    "    for pos, equals in Stats_Per_Pos.items()\n",
    "    #if pos in LIMIT_TO_POS\n",
    "])\n",
    "\n",
    "#Impact means: contribution to total error (in %)\n",
    "# TODO: réfléchir meilleur mesure\n",
    "PosLemmaDetails.sort_values(\"Contribution relative\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "PosLemmaDetails.sort_values(\"Impact\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f167c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[REF:ChastVergiS_A_69]</td>\n",
       "      <td>(Error Rate: 38.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[REF:PsLorrA_672]</td>\n",
       "      <td>(Error Rate: 30.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[REF:PerNeslesTabJ_602]</td>\n",
       "      <td>(Error Rate: 30.0%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[REF:MerlinP_956]</td>\n",
       "      <td>(Error Rate: 27.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[REF:MerlinP_1603]</td>\n",
       "      <td>(Error Rate: 26.1%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[REF:IpH_603]</td>\n",
       "      <td>(Error Rate: 30.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[REF:IpH_3634]</td>\n",
       "      <td>(Error Rate: 35.8%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[REF:IpH_3829]</td>\n",
       "      <td>(Error Rate: 31.9%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[REF:IpH_5979]</td>\n",
       "      <td>(Error Rate: 29.5%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[REF:IpH_6385]</td>\n",
       "      <td>(Error Rate: 41.3%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0                     1\n",
       "0    [REF:ChastVergiS_A_69]   (Error Rate: 38.5%)\n",
       "1         [REF:PsLorrA_672]   (Error Rate: 30.9%)\n",
       "2   [REF:PerNeslesTabJ_602]   (Error Rate: 30.0%)\n",
       "3         [REF:MerlinP_956]   (Error Rate: 27.8%)\n",
       "4        [REF:MerlinP_1603]   (Error Rate: 26.1%)\n",
       "..                      ...                   ...\n",
       "57            [REF:IpH_603]   (Error Rate: 30.8%)\n",
       "58           [REF:IpH_3634]   (Error Rate: 35.8%)\n",
       "59           [REF:IpH_3829]   (Error Rate: 31.9%)\n",
       "60           [REF:IpH_5979]   (Error Rate: 29.5%)\n",
       "61           [REF:IpH_6385]   (Error Rate: 41.3%)\n",
       "\n",
       "[62 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##mes modifs\n",
    "Impact_Acc_Per_Pos2 = Impact_Acc_Per_Pos.reset_index(level=0)\n",
    "Impact_Acc_Per_Pos3 = Impact_Acc_Per_Pos2['index'].str.split('\\n', expand=True)\n",
    "Impact_Acc_Per_Pos3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e70ced9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Impact_Acc_Per_Pos3[\"error\"] = Impact_Acc_Per_Pos3[1].str.extract(r'\\(Error Rate: (.*)%\\)')\n",
    "Impact_Acc_Per_Pos3.index = Impact_Acc_Per_Pos3[0].str.extract(r'\\[REF:(.*)\\]')\n",
    "Impact_Acc_Per_Pos3\n",
    "type(Impact_Acc_Per_Pos3)\n",
    "#Impact_Acc_Per_Pos3[\"error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4c8313d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [130]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Impact_Acc_Per_Pos3[\u001b[43mImpact_Acc_Per_Pos3\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3024\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3024\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3026\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/range.py:354\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mget_loc(key, method\u001b[38;5;241m=\u001b[39mmethod, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'error'"
     ]
    }
   ],
   "source": [
    "Impact_Acc_Per_Pos3[Impact_Acc_Per_Pos3[\"error\"]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d7b9d1d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-d0e5fb3f4cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mImpact_Acc_Per_Pos4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImpact_Acc_Per_Pos3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"error\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mImpact_Acc_Per_Pos4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdfPlot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImpact_Acc_Per_Pos4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImpact_Acc_Per_Pos4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "Impact_Acc_Per_Pos4 = Impact_Acc_Per_Pos3[\"error\"]\n",
    "Impact_Acc_Per_Pos4\n",
    "dfPlot = Impact_Acc_Per_Pos4[Impact_Acc_Per_Pos4.columns].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2f96f857",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Inconsistent shape between the condition and the input (got (62, 1) and (62,))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-6e9d87cc1b10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcubehelix_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_cmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImpact_Acc_Per_Pos4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, cmap=cmap)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pourcentage d'erreurs occasionnées par POS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[1;32m    541\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                           yticklabels, mask)\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;31m# Add the pcolormesh kwargs here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_matrix_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mplot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Get good names for the rows and columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36mmasked_where\u001b[0;34m(condition, a, copy)\u001b[0m\n\u001b[1;32m   1934\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcshape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mashape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m         raise IndexError(\"Inconsistent shape between the condition and the input\"\n\u001b[0;32m-> 1936\u001b[0;31m                          \" (got %s and %s)\" % (cshape, ashape))\n\u001b[0m\u001b[1;32m   1937\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m         \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Inconsistent shape between the condition and the input (got (62, 1) and (62,))"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'})\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "cmap = sns.cubehelix_palette(250, hue=0.05, rot=0, light=1, dark=0, as_cmap=True)\n",
    "ax = sns.heatmap(Impact_Acc_Per_Pos4, annot=True)#, cmap=cmap)\n",
    "ax.set_title(\"Pourcentage d'erreurs occasionnées par POS\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a14bbae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function defaultdict.items>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextTitleSize[text_id].size\n",
    "TextTitleSize[text_id].error_rate\n",
    "Stats_Per_Pos.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "21f3322e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, defaultdict(<class 'list'>, {'_': [1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1]})), (1, defaultdict(<class 'list'>, {'_': [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1]})), (2, defaultdict(<class 'list'>, {'_': [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1]})), (3, defaultdict(<class 'list'>, {'_': [0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1]})), (4, defaultdict(<class 'list'>, {'_': [0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]})), (5, defaultdict(<class 'list'>, {'_': [0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1]})), (6, defaultdict(<class 'list'>, {'_': [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1]})), (7, defaultdict(<class 'list'>, {'_': [0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]})), (8, defaultdict(<class 'list'>, {'_': [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0]})), (9, defaultdict(<class 'list'>, {'_': [1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0]})), (10, defaultdict(<class 'list'>, {'_': [0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]})), (11, defaultdict(<class 'list'>, {'_': [0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]})), (12, defaultdict(<class 'list'>, {'_': [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0]})), (13, defaultdict(<class 'list'>, {'_': [1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]})), (14, defaultdict(<class 'list'>, {'_': [1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1]})), (15, defaultdict(<class 'list'>, {'_': [0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1]})), (16, defaultdict(<class 'list'>, {'_': [1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1]})), (17, defaultdict(<class 'list'>, {'_': [0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1]})), (18, defaultdict(<class 'list'>, {'_': [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1]})), (19, defaultdict(<class 'list'>, {'_': [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1]})), (20, defaultdict(<class 'list'>, {'_': [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]})), (21, defaultdict(<class 'list'>, {'_': [1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1]})), (22, defaultdict(<class 'list'>, {'_': [1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1]})), (23, defaultdict(<class 'list'>, {'_': [0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1]})), (24, defaultdict(<class 'list'>, {'_': [0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1]})), (25, defaultdict(<class 'list'>, {'_': [1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0]})), (26, defaultdict(<class 'list'>, {'_': [0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1]})), (27, defaultdict(<class 'list'>, {'_': [1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1]})), (28, defaultdict(<class 'list'>, {'_': [1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]})), (29, defaultdict(<class 'list'>, {'_': [0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1]})), (30, defaultdict(<class 'list'>, {'_': [1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]})), (31, defaultdict(<class 'list'>, {'_': [1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1]})), (32, defaultdict(<class 'list'>, {'_': [0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1]})), (33, defaultdict(<class 'list'>, {'_': [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1]})), (34, defaultdict(<class 'list'>, {'_': [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]})), (35, defaultdict(<class 'list'>, {'_': [0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1]})), (36, defaultdict(<class 'list'>, {'_': [1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1]})), (37, defaultdict(<class 'list'>, {'_': [1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0]})), (38, defaultdict(<class 'list'>, {'_': [1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0]})), (39, defaultdict(<class 'list'>, {'_': [1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1]})), (40, defaultdict(<class 'list'>, {'_': [0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1]})), (41, defaultdict(<class 'list'>, {'_': [0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1]})), (42, defaultdict(<class 'list'>, {'_': [1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0]})), (43, defaultdict(<class 'list'>, {'_': [0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1]})), (44, defaultdict(<class 'list'>, {'_': [1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0]})), (45, defaultdict(<class 'list'>, {'_': [1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1]})), (46, defaultdict(<class 'list'>, {'_': [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1]})), (47, defaultdict(<class 'list'>, {'_': [1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1]})), (48, defaultdict(<class 'list'>, {'_': [0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]})), (49, defaultdict(<class 'list'>, {'_': [1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]})), (50, defaultdict(<class 'list'>, {'_': [1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1]})), (51, defaultdict(<class 'list'>, {'_': [0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1]})), (52, defaultdict(<class 'list'>, {'_': [1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1]})), (53, defaultdict(<class 'list'>, {'_': [0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]})), (54, defaultdict(<class 'list'>, {'_': [1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0]})), (55, defaultdict(<class 'list'>, {'_': [0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1]})), (56, defaultdict(<class 'list'>, {'_': [0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1]})), (57, defaultdict(<class 'list'>, {'_': [1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1]})), (58, defaultdict(<class 'list'>, {'_': [0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1]})), (59, defaultdict(<class 'list'>, {'_': [0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1]})), (60, defaultdict(<class 'list'>, {'_': [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1]})), (61, defaultdict(<class 'list'>, {'_': [1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]}))])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ScatterPos = DataFrame([\n",
    "    {\n",
    "        \"POS\": pos,\n",
    "        \"Corpus\": len(equals)/TextTitleSize[text_id].size, \n",
    "        \"desErreurs\": compute_accuracy(\n",
    "            equals,\n",
    "            TextTitleSize[text_id].size,\n",
    "            TextTitleSize[text_id].error_rate\n",
    "        )\n",
    "    }\n",
    "    for text_id, texts_values in Stats_Per_Pos.items()\n",
    "        for pos, equals in texts_values.items()\n",
    "        if pos in LIMIT_TO_POS\n",
    "])\n",
    "\n",
    "ScatterPos\n",
    "#ScatterPos[\"Impact\"] = ScatterPos[\"% des Erreurs\"] / ScatterPos[\"% Corpus\"] \n",
    "\n",
    "#texts_values.items\n",
    "Stats_Per_Pos.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc7d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,7), dpi=300)\n",
    "# Draw plotbot\n",
    "ScatterPos.boxplot(ax=ax1, column=\"Impact\", by=\"POS\")\n",
    "ax1.set_title(label=\"\")\n",
    "ax1.axhline(y=1, label=\"Distribution normale\", linestyle=\":\")\n",
    "ax1.set_ylabel(\"Impact\")\n",
    "# ax1.text(y=0.8, x=5.6, s=\"Distribution\\nnormale\")\n",
    "ax1.grid(True, color='b', linestyle='--', linewidth=0.2)\n",
    "\n",
    "# Draw scatter\n",
    "ax2 = sns.scatterplot(\n",
    "    x=\"% Corpus\", y=\"% des Erreurs\", style=\"POS\", \n",
    "    data=ScatterPos, alpha=0.8,\n",
    "    color=\"g\",\n",
    "    ax=ax2\n",
    ")\n",
    "x = np.linspace(0, 0.4)\n",
    "line = ax2.plot(x, x, linestyle=':', color=\"b\", label=\"Distribution\\nnormale\")\n",
    "# line_patch = mpatches.Patch(color='blue', linestyle=\"--\", label=\"Distribution\\nnormale\")\n",
    "\n",
    "handles, labels = ax2.get_legend_handles_labels()\n",
    "ax2.legend(bbox_to_anchor=(1, 1), loc=1, borderaxespad=0, handles=handles)\n",
    "\n",
    "fig.suptitle(\"\")\n",
    "fig.show()\n",
    "\n",
    "nompro =  ScatterPos.loc[ScatterPos[\"POS\"]==\"NOMpro\"][\"Impact\"]\n",
    "print(nompro.median())#, nompro)\n",
    "nomcom =  ScatterPos.loc[ScatterPos[\"POS\"]==\"NOMcom\"][\"Impact\"]\n",
    "print(nomcom.median())#, nomcom)\n",
    "ver =  ScatterPos.loc[ScatterPos[\"POS\"]==\"VER\"][\"Impact\"]\n",
    "print(nomcom.median())#, nomcom)\n",
    "\n",
    "FullDistrib = DataFrame([\n",
    "    {\n",
    "        \"POS\": pos,\n",
    "        \"% Corpus\": len(equals)/TextTitleSize[text_id].size, \n",
    "        \"% des Erreurs\": compute_accuracy(\n",
    "            equals,\n",
    "            TextTitleSize[text_id].size,\n",
    "            TextTitleSize[text_id].error_rate\n",
    "        )\n",
    "    }\n",
    "    for text_id, texts_values in Stats_Per_Pos.items()\n",
    "        for pos, equals in texts_values.items()\n",
    "])\n",
    "FullDistrib[\"Impact\"] = ScatterPos[\"% des Erreurs\"] / ScatterPos[\"% Corpus\"]\n",
    "FDGB = FullDistrib.groupby(\"POS\").median()\n",
    "print(FDGB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
